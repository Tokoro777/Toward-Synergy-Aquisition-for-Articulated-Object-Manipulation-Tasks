{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの作成\n",
    "+ chainer学習用のデータセットを作成.\n",
    "+ shapeはできるだけ変更しないで, {中間出力, 関節角度(量子化済み＆量子化前),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "import h5py\n",
    "\n",
    "\n",
    "from logging import getLogger, basicConfig, DEBUG, INFO\n",
    "logger = getLogger(__name__)\n",
    "LOG_FMT = \"{asctime} | {levelname:<5s} | {name} | {message}\"\n",
    "basicConfig(level=INFO, format=LOG_FMT, style=\"{\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(X,th_min=-1., th_max=1.):\n",
    "    \"\"\" 量子化の実行\n",
    "    \n",
    "    Args.\n",
    "    -----\n",
    "    - x: float\n",
    "    - th_min/th_max: float, threshhold [unit=degree]\n",
    "    \"\"\"\n",
    "    _X = X.copy()\n",
    "    _X[X < th_min] = -1.\n",
    "    _X[X > th_max] =  1.\n",
    "    _X[(X >= th_min) & (X<= th_max)] = 0\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_min= -0.5\n",
    "th_max=  0.5\n",
    "\n",
    "def threading_clbk(ps):\n",
    "    (path_in, path_out,) = ps\n",
    "    \n",
    "    \n",
    "    logger.info(\"Start: Load from {}\".format(path_in))\n",
    "    # Load File\n",
    "    with h5py.File(path_in, 'r') as f:\n",
    "        A  = np.array(f[\"action\"],)\n",
    "        FC = np.array(f[\"fc\"])\n",
    "    logger.info(\"Start: A={}, FC={} [from {}]\".format(A.shape, FC.shape, path_in))\n",
    "        \n",
    "    # 量子化 & Onehot Encoding\n",
    "    As = resampling(A,th_min=th_min, th_max=th_max)\n",
    "\n",
    "    shape = list(As.shape) + [3]\n",
    "    As_onehot = np.eye(3)[As.ravel().astype(int)+1]\n",
    "    As_onehot  = As_onehot.reshape(shape)\n",
    "    \n",
    "    # Write\n",
    "    with h5py.File(path_out, 'w') as f:\n",
    "        f.create_dataset(\"fc\", data=FC)\n",
    "        f.create_group('action')\n",
    "        f[\"action\"].create_dataset(\"raw\", data=A)\n",
    "        #f[\"action\"].create_dataset(\"resampled\", data=As)\n",
    "        f[\"action\"].create_dataset(\"onehot\", data=As_onehot)\n",
    "    logger.info(\"Finish: Write to {}\".format(path_out))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-09 09:50:04,795 | INFO  | __main__ | Start: Load from /root/dataStore/grasp_v1/episodes/epoch0.h5\n",
      "2019-01-09 09:50:04,799 | INFO  | __main__ | Start: A=(10, 2, 100, 21), FC=(10, 2, 100, 256) [from /root/dataStore/grasp_v1/episodes/epoch0.h5]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = '/root/dataStore/grasp_v1/Inputs/epoch0.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f0c1f8ececb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpath_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/dataStore/grasp_v1/Inputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch0.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mthreading_clbk\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a78e8c9b5caa>\u001b[0m in \u001b[0;36mthreading_clbk\u001b[0;34m(ps)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Write\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '/root/dataStore/grasp_v1/Inputs/epoch0.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "\"\"\" Apply for single episode\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "\n",
    "path_in  = os.path.join(\"/root/dataStore/grasp_v1/episodes\", \"epoch0.h5\")\n",
    "path_out = os.path.join(\"/root/dataStore/grasp_v1/Inputs\", \"epoch0.h5\")\n",
    "\n",
    "threading_clbk( (path_in, path_out,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/dataStore/tmp2/episodes/epoch0.h5', '/root/dataStore/tmp2/episodes/epoch1.h5', '/root/dataStore/tmp2/episodes/epoch2.h5']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/root/dataStore/tmp2/episodes/epoch0.h5',\n",
       "  '/root/dataStore/tmp2/Inputs/epoch0.h5'),\n",
       " ('/root/dataStore/tmp2/episodes/epoch1.h5',\n",
       "  '/root/dataStore/tmp2/Inputs/epoch1.h5'),\n",
       " ('/root/dataStore/tmp2/episodes/epoch2.h5',\n",
       "  '/root/dataStore/tmp2/Inputs/epoch2.h5')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Execute in paralel\n",
    "\"\"\"\n",
    "import glob\n",
    "\n",
    "dir_in  = \"/root/dataStore/tmp2/episodes\"\n",
    "dir_out = \"/root/dataStore/tmp2/Inputs\"\n",
    "\n",
    "file_list = list(glob.glob(os.path.join(dir_in, \"*.h5\")))\n",
    "file_list.sort()\n",
    "print(file_list)\n",
    "\n",
    "file_list = [(path_in, os.path.join(dir_out, path_in.split(\"/\")[-1])) for path_in in file_list]\n",
    "display(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-27 07:55:41,312 | INFO  | __main__ | Start Load OPP Dataset [3files]\n",
      "2018-12-27 07:55:41,313 | INFO  | __main__ | Start: Load from /root/dataStore/tmp2/episodes/epoch0.h5\n",
      "2018-12-27 07:55:41,313 | INFO  | __main__ | Start: Load from /root/dataStore/tmp2/episodes/epoch1.h5\n",
      "2018-12-27 07:55:41,313 | INFO  | __main__ | Start: Load from /root/dataStore/tmp2/episodes/epoch2.h5\n",
      "2018-12-27 07:55:41,317 | INFO  | __main__ | Start: A=(10, 2, 100, 20), FC=(10, 2, 100, 256) [from /root/dataStore/tmp2/episodes/epoch0.h5]\n",
      "2018-12-27 07:55:41,320 | INFO  | __main__ | Start: A=(10, 2, 100, 20), FC=(10, 2, 100, 256) [from /root/dataStore/tmp2/episodes/epoch1.h5]\n",
      "2018-12-27 07:55:41,321 | INFO  | __main__ | Start: A=(10, 2, 100, 20), FC=(10, 2, 100, 256) [from /root/dataStore/tmp2/episodes/epoch2.h5]\n",
      "2018-12-27 07:55:41,326 | INFO  | __main__ | Finish: Write to /root/dataStore/tmp2/Inputs/epoch0.h5\n",
      "2018-12-27 07:55:41,330 | INFO  | __main__ | Finish: Write to /root/dataStore/tmp2/Inputs/epoch1.h5\n",
      "2018-12-27 07:55:41,333 | INFO  | __main__ | Finish: Write to /root/dataStore/tmp2/Inputs/epoch2.h5\n",
      "2018-12-27 07:55:41,335 | INFO  | __main__ | Thread ... Finish!! [Results=3]\n",
      "2018-12-27 07:55:41,336 | INFO  | __main__ | Finish!!\n"
     ]
    }
   ],
   "source": [
    "# Load files using Threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "thread_list   = []\n",
    "max_worker = 5\n",
    "logger.info(\"Start Load OPP Dataset [{}files]\".format(len(file_list)))    \n",
    "with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "    ret = executor.map(threading_clbk, file_list)\n",
    "logger.info(\"Thread ... Finish!! [Results={}]\".format(len(list(ret))))\n",
    "logger.info(\"Finish!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作成したデータの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 100, 20)\n"
     ]
    }
   ],
   "source": [
    "dir_in  = \"/root/dataStore/tmp2/episodes\"\n",
    "dir_out = \"/root/dataStore/tmp2/Inputs\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "filename = os.path.join(\"/root/dataStore\", \"test\", \"Inputs\", \"test\", \"epoch8.h5\")\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    A = np.array(f[\"action/resampled\"],)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1., -1.,  0., ...,  1.,  1., -1.],\n",
       "         [ 0., -1.,  0., ...,  0.,  1., -1.],\n",
       "         [ 0., -1., -1., ..., -1.,  1., -1.],\n",
       "         ...,\n",
       "         [-1., -1.,  0., ..., -1.,  1., -1.],\n",
       "         [-1., -1.,  0., ..., -1.,  1., -1.],\n",
       "         [-1., -1.,  0., ..., -1.,  1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1., ...,  1.,  1., -1.],\n",
       "         [ 1.,  1.,  1., ...,  1.,  1., -1.],\n",
       "         [ 1.,  1.,  1., ...,  1.,  1., -1.],\n",
       "         ...,\n",
       "         [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1., ...,  1.,  1.,  1.]]],\n",
       "\n",
       "\n",
       "       [[[-1.,  1.,  1., ...,  1.,  1., -1.],\n",
       "         [-1.,  1.,  1., ...,  0.,  0., -1.],\n",
       "         [-1.,  1.,  1., ..., -1.,  1., -1.],\n",
       "         ...,\n",
       "         [-1.,  1.,  0., ...,  0.,  1., -1.],\n",
       "         [-1.,  1.,  0., ...,  0.,  1., -1.],\n",
       "         [-1.,  1.,  0., ...,  0.,  1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1., ..., -1.,  1., -1.],\n",
       "         [ 1., -1.,  1., ..., -1.,  1., -1.],\n",
       "         [ 1., -1.,  0., ..., -1.,  1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1., ..., -1.,  1., -1.],\n",
       "         [-1., -1., -1., ..., -1.,  1., -1.],\n",
       "         [-1., -1., -1., ..., -1.,  1., -1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
